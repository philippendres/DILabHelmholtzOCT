{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interactive application for segmenting OCT data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just change the checkpoint path, run the following cells and follow the link in the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#backend\n",
    "import torch\n",
    "from transformers import SamModel, SamProcessor\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "processor = SamProcessor.from_pretrained(\"facebook/sam-vit-base\")\n",
    "model = SamModel.from_pretrained(\"facebook/sam-vit-base\").to(device)\n",
    "checkpoint_path = \"/vol/data/models/custom5e-05 lr,1e-04 wd,2 bs, diceCE loss, grayscale, 24-02-23_17.35.30_24-02-23_17.35.30\"\n",
    "model.load_state_dict(torch.load(checkpoint_path +\".pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(img, pixel, prompt_type):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        if (prompt_type==\"points\"):\n",
    "            inputs = processor(img, input_points= [[pixel]], return_tensors=\"pt\").to(device)\n",
    "        else:\n",
    "            inputs = processor(img, input_boxes=[[pixel]], return_tensors=\"pt\").to(device)\n",
    "        outputs= model(**inputs, multimask_output=False)\n",
    "        masks = F.interpolate(outputs.pred_masks.squeeze(2), (1024,1024), mode=\"bilinear\", align_corners=False)\n",
    "        masks = masks[..., : inputs[\"reshaped_input_sizes\"][0,0], : inputs[\"reshaped_input_sizes\"][0,1]]\n",
    "        masks = F.interpolate(masks, (inputs[\"original_sizes\"][0,0],inputs[\"original_sizes\"][0,1]), mode=\"bilinear\", align_corners=False)\n",
    "        masks = torch.sigmoid(masks).cpu().squeeze().numpy()\n",
    "        binary_masks = (masks > 0.5).astype(np.uint8)\n",
    "    return binary_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "from gradio_image_prompter import ImagePrompter\n",
    "import numpy as np\n",
    "def segment(inputs):\n",
    "    img = inputs[\"image\"]\n",
    "    masks = []\n",
    "    for i in range(len(inputs[\"points\"])):\n",
    "        pixel = list(map(int, inputs[\"points\"][i]))\n",
    "        prompt = [pixel[0], pixel[1], pixel[3],pixel[4]]\n",
    "        print(prompt)\n",
    "        if pixel[3]==0 and pixel[4]==0:\n",
    "            #point prompt\n",
    "            mask = inference(img, [prompt[0], prompt[1]], \"points\")\n",
    "            point = np.zeros(img.shape[:2])\n",
    "            point[prompt[1]-1:prompt[1]+2, prompt[0]-1:prompt[0]+2] = 1\n",
    "            masks.append((point,\"point\"))\n",
    "            masks.append((mask, \"mask\"))\n",
    "        else:\n",
    "            #bbox prompt\n",
    "            mask = inference(img, prompt, \"bbox\")\n",
    "            masks.append((prompt,\"box\"))\n",
    "            masks.append((mask, \"mask\"))\n",
    "    return (img, masks)\n",
    "\n",
    "demo = gr.Interface(\n",
    "    segment,\n",
    "    ImagePrompter(show_label=True),\n",
    "    [gr.AnnotatedImage(\n",
    "            color_map={\"mask\": \"#ff0000\", \"box\": \"#00ff00\", \"point\": \"#0000ff\"}\n",
    "        )],\n",
    ")\n",
    "demo.launch(share=True)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
